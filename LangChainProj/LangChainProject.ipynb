{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YIs4bngsPm8"
   },
   "source": [
    "## <font color=blue> TASK 1: Install and setup LangChain\n",
    "Welcome to this project notebook, which will serve as your guide to constructing your inaugural Generative AI application. Within this notebook, you'll encounter concise descriptions of each task to enhance your comprehension of the sequence. Our initial task commences with the importation of essential libraries required for this project.\n",
    "\n",
    "***Note: Before importing the libraries please ensure that all the library modules such as Langchain, Streamlit, PyPdf and other required libraries are installed on this notebook by running the pip command as shown below.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wnvxw5okxYjT",
    "outputId": "fadee241-7a02-4775-c4b1-0b1857d4ce8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.6)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.59)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.2.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.30.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (0.1.59)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (2.6.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (8.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.10.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain_openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.46->langchain_openai) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain_openai) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (1.26.18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.10.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.34.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.8.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.24.4)\n",
      "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.2.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.24.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.10.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.4)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.21.1)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.6)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.0)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.59)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.24.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (0.2.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (2.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.10.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (2.16.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m734.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain_community\n",
      "Successfully installed langchain_community-0.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#For installing the Langchain module associated with OpenAI LLM model\n",
    "!pip install langchain\n",
    "!pip install langchain_openai\n",
    "#For installing the Python library responsible for PDF upload\n",
    "!pip install pypdf\n",
    "#For installing the library responsible for web app development\n",
    "!pip install streamlit\n",
    "#For installing tokeniser library that asists with converting text strings into tokens recognizable by OpenAI models\n",
    "!pip install tiktoken\n",
    "#For installing the library used for invoking the environment file containing secret API key\n",
    "!pip install python-dotenv\n",
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bJ0AR0gorTlF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvtUejaS8v8T"
   },
   "source": [
    "## <font color=blue> Load OpenAI API Key to access LLM model\n",
    "\n",
    "## <font color=black>\n",
    "1. Go to https://platform.openai.com/api-keys\n",
    "2. Click on the '+ Creat new secret key button'\n",
    "3. Enter an identifier name(optional) and click on the \"Create secret key\" button\n",
    "4. Copy the API key to be used in the API.env file that you need to upload to Google Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qtlBVZonvkf8"
   },
   "outputs": [],
   "source": [
    "# Load the .env file and invoke the secret API key from the file\n",
    "dotenv.load_dotenv('secretapi.env')\n",
    "OpenAI.api_key = os.getenv(\"SECRET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRjptllP7Xgb"
   },
   "source": [
    "# <font color=blue> Load PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FL4FtXMkvocT"
   },
   "outputs": [],
   "source": [
    "pdf_url = \"https://www.medrxiv.org/content/10.1101/2021.07.15.21260605v1.full.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_url)\n",
    "pages = loader.load_and_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HEGnGRAe_op2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "--------------------------------------------------\n",
      "COVID -19 Chest X-Ray Image  Classification  Using Deep Learning\n",
      "Gunther Correia Bacellar,1 Mallikarjuna Chandrappa,1 Rajlakshman Kulkarni,1 Soumava Dey1* \n",
      "Department of Computer Science, University of Illinois at Urbana -Champaign, Urbana, IL, 61801, USA   \n",
      "*Correspondence: soumava2@illinois.edu ; soumavadey87@gmail.com  \n",
      "               \n",
      "ABSTRACT  \n",
      "The rise of the coronavirus disease 2019 (COVID -19) pandemic has made it necessary to improve existing medical screening \n",
      "and clinical management of this disease. While  COVID -19 patients are known to exhibit  a variety of symptoms, the major \n",
      "symptoms include  fever, cough, and fatigue. Since these symptoms also appear in pneumonia patients, this creates \n",
      "complications in COVID -19 detection especially during the flu season. Early studies identified abnormalities in chest X -ray \n",
      "images of COVID -19 infected patient s that could be beneficial for disease diagnosis. Therefore, chest X -ray image -based \n",
      "disease classification has emerged as an alternative to aid medical diagnosis. However, m anual detection of COVID -19 from a \n",
      "set of chest X -ray images comprising both COVID -19 and pneumonia cases is cumbersome and prone to huma n error. Thus,  \n",
      "artificial intelligence techniques powered by deep learning algorithms,  which  learn from radiography images and predict \n",
      "presence of COVID -19 have potential to enhance current diagnosis  process. Towards this purpose, here we implemented a set \n",
      "of deep learning pre -trained models such as ResNet, VGG, Inception and EfficientNet in conjunction with developing a \n",
      "computer vision AI system based on our own convolutional neural network (CNN) model: Deep Learning in Healthcare ( DLH )-\n",
      "COVID. All  these CNN models cater to image classification exercise.  We used publicly available resources of 6,432 images \n",
      "and further strengthened our model by tuning hyperparameters to provide better generalization dur ing the model validation \n",
      "phase. Our final  DLH -COVID model yielded  the highest  accuracy of 96% in detection of COVID -19 from chest X -ray images \n",
      "when compared to images of both pneumonia -affected and healthy individuals.  Given the practicality of acquiring c hest X -ray \n",
      "images by patients, we also developed a web application (link: https://toad.li/xray ) based on our model to directly enable users \n",
      "to upload chest X -ray images and detect the presence of COVID -19 within a few s econds . Taken together, here we introduce \n",
      "a state -of-the-art artificial intelligence -based system for efficient COVID -19 detection and a user -friendly application  that has \n",
      "the capacity  to become a rapid COVID -19 diagnosis method in the near future.\n",
      " \n",
      "Keywords : COVID -19, Coronavirus detection, Deep learning, X -ray, Pneumonia, Classification  \n",
      " \n",
      "1. INTRODUCTIO N    \n",
      "The COVID -19 is a viral infection that causes severe \n",
      "respiratory illness ranging from common cold to life \n",
      "threating disease s like Severe Acute Respiratory Syndrome \n",
      "(SARS) and Middle East Respiratory Syndrome (MERS). \n",
      "According to reports from the World Health Organization \n",
      "(WHO), major symptoms of COVID -19 are s imilar to  that \n",
      "of common flu: fever, tiredness, dry cough, shortness of \n",
      "breath, aches and sore throat  [1,2]. The similarities between \n",
      "COVID -19 and flu symptoms causes difficulties in detection \n",
      "of the coro navirus at early stages. It was found in some \n",
      "patients that the coronavirus, like other viruses and bacteria, \n",
      "also causes pneumonia, and the treatment for coronavirus \n",
      "induced pneumonia is different from other types of \n",
      "pneumonia. Moreover, bacterial pneumon ia infected \n",
      "patients require antibiotic treatment whereas viral \n",
      "pneumonia cases can be treated by intensive care [3]. \n",
      "Therefore, accurate and timely diagnosis of COVID -19 \n",
      "induced pneumonia is very important to save human lives as \n",
      "well as curbing the pandem ic outbreak across the world.  \n",
      "The WHO approved method of testing COVID -19 is \n",
      "the reverse transcription polymerase chain reaction (RT -\n"
     ]
    }
   ],
   "source": [
    "#number of pages\n",
    "print(len(pages))\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "\n",
    "#view page content\n",
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyDp0eJj_hNd"
   },
   "source": [
    "## <font color=blue> TASK 2: Define the summarize pdf function\n",
    "Define the main function that will take pdf file path as an input and generate a summary of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kON5tJmk09Mp"
   },
   "outputs": [],
   "source": [
    "def summarize_pdf(pdf_file_path, chunk_size, chunk_overlap):\n",
    "\n",
    "    #Instantiate LLM model gpt-3.5-turbo-16k\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
    "    #Load PDF file\n",
    "    loader = PyPDFLoader(pdf_file_path)\n",
    "    docs_raw = loader.load()\n",
    "\n",
    "    #Create multiple documents\n",
    "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
    "\n",
    "    #Split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
    "\n",
    "    #Summarize the chunks (map_reduce method takes longer to execute)\n",
    "    chain = load_summarize_chain(llm, chunk_type=\"stuff\")\n",
    "    \n",
    "    #Return the summary\n",
    "    summary = chain.invoke(docs_chunks, return_only_outputs=True)\n",
    "    return summary['output_text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jP624HFsZyT"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "zZsZ5TGMM-WS"
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for StuffDocumentsChain\nchunk_type\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#print summary by using chain type stuff or map_reduce\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Chunk size and chunk overlap values set to random value\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msummarize_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m, in \u001b[0;36msummarize_pdf\u001b[0;34m(pdf_file_path, chunk_size, chunk_overlap)\u001b[0m\n\u001b[1;32m     14\u001b[0m docs_chunks \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39mcreate_documents(docs_raw_text)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#Summarize the chunks (map_reduce method takes longer to execute)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m chain \u001b[38;5;241m=\u001b[39m \u001b[43mload_summarize_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstuff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#Return the summary\u001b[39;00m\n\u001b[1;32m     20\u001b[0m summary \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke(docs_chunks, return_only_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/summarize/chain.py:166\u001b[0m, in \u001b[0;36mload_summarize_chain\u001b[0;34m(llm, chain_type, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chain_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loader_mapping:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unsupported chain type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchain_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloader_mapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    165\u001b[0m     )\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchain_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/summarize/chain.py:35\u001b[0m, in \u001b[0;36m_load_stuff_chain\u001b[0;34m(llm, prompt, document_variable_name, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mprompt, verbose\u001b[38;5;241m=\u001b[39mverbose)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# TODO: document prompt\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStuffDocumentsChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocument_variable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocument_variable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for StuffDocumentsChain\nchunk_type\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "#print summary by using chain type stuff or map_reduce\n",
    "#Chunk size and chunk overlap values set to random value\n",
    "\n",
    "print(summarize_pdf(pdf_url, 1000, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cvnt8H-L3Yzb"
   },
   "source": [
    "## <font color=blue> TASK 3: Add Prompt template to the summarizer function\n",
    "Leveraging prompt templates to extract key information from the reserach paper in more guided manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_s2a87sV4Hkl"
   },
   "source": [
    "## <font color=blue> Define Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Wy1_iJlfQRR"
   },
   "source": [
    "### <font color=black> Prompt Template for Stuffing chain type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Zac7tS6p3YKU"
   },
   "outputs": [],
   "source": [
    "map_prompt_template = \"\"\"\n",
    "                       Write a summary of the research paper for an\n",
    "                       artficial intelligence researcher that includes\n",
    "                       main points and any important details in bullet points.{text}\n",
    "                      \"\"\"\n",
    "\n",
    "map_prompt ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Il7HTR6pfjsF"
   },
   "source": [
    "### <font color=black> Add Combo Template for Map_Reduce chain type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AaZoSIMDfMPu"
   },
   "outputs": [],
   "source": [
    "combine_prompt_template =\n",
    "\n",
    "combine_prompt ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6xyYdjJZEJJs"
   },
   "outputs": [],
   "source": [
    "#Modify the custom function to add the prompt templates\n",
    "\n",
    "def summarize_pdf(pdf_file_path, chunk_size, chunk_overlap):\n",
    "\n",
    "    #Instantiate LLM model gpt-3.5-turbo-16k\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
    "\n",
    "    #Load PDF file\n",
    "    loader = PyPDFLoader(pdf_file_path)\n",
    "    docs_raw = loader.load()\n",
    "\n",
    "    #Create multiple documents\n",
    "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
    "\n",
    "    #Split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
    "\n",
    "    #Summarize the chunks\n",
    "    chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "\n",
    "    #Return the summary\n",
    "    summary = chain.invoke(docs_chunks, return_only_outputs=True)\n",
    "    return summary['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2bNEpmcPG0w"
   },
   "outputs": [],
   "source": [
    "#print summary using the map_prompt and combine prompt\n",
    "#Increasing the chunk size value might reduce the overall summarization time with map_reduce method\n",
    "print(summarize_pdf(pdf_url, 2000, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XUnEVtU849_"
   },
   "source": [
    "## <font color=blue> TASK 4: Build and test a GenAI app for PDF summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urhXeIwaS6RN"
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import streamlit as st\n",
    "\n",
    "\n",
    "# Load the .env file and invoke the secret API key from the file\n",
    "dotenv.load_dotenv('API.env')\n",
    "OpenAI.api_key = os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "#summarize_pdf function\n",
    "\n",
    "def summarize_pdf(pdf_file_path, chunk_size, chunk_overlap, prompt):\n",
    "    #Instantiate LLM model gpt-3.5-turbo-16k\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
    "\n",
    "    #Load PDF file\n",
    "    loader = PyPDFLoader(pdf_file_path)\n",
    "    docs_raw = loader.load()\n",
    "\n",
    "    #Create multiple documents\n",
    "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
    "\n",
    "    #Split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
    "\n",
    "    #Summarize the chunks\n",
    "    chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt = prompt)\n",
    "    #Return the summary\n",
    "    summary = chain.invoke(docs_chunks, return_only_outputs=True)\n",
    "    return summary['output_text']\n",
    "\n",
    "#streamlit app main() function\n",
    "\n",
    "def main():\n",
    "    #Set page config and title\n",
    "\n",
    "\n",
    "    #Input pdf file path\n",
    "\n",
    "\n",
    "    #prompt input\n",
    "\n",
    "    #Summarize button\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10C8V-CIL4Ti"
   },
   "source": [
    "## <font color=blue> Launch Streamlit app from Google Colab\n",
    "\n",
    "The following lines of code would enable users to launch Streamlit app from Google Colab using [ngrok service](https://ngrok.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaPE0T2iDzwu"
   },
   "outputs": [],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Brgmtoc7CVKx"
   },
   "outputs": [],
   "source": [
    "!unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hle-PIMoQfLs"
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 8501 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7C6dydMS06y"
   },
   "outputs": [],
   "source": [
    "!wget -q -O - ipv4.icanhazip.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1Rduaz0TG-Y"
   },
   "outputs": [],
   "source": [
    "!streamlit run app.py & npx localtunnel --port 8501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJtA0iPfgBn_"
   },
   "source": [
    "## <font color=blue> FINAL TASK: Cumulative Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFTCcg_COEie"
   },
   "source": [
    "Click the link to explore useful Streamlit library functions:\n",
    "https://docs.streamlit.io/library/cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PiEdC80-gP-k"
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import streamlit as st\n",
    "\n",
    "# Load the .env file and invoke the secret API key from the file\n",
    "dotenv.load_dotenv('API.env')\n",
    "OpenAI.api_key = os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "#summarize_pdf function\n",
    "\n",
    "def summarize_pdf(pdf_file_path, chunk_size, chunk_overlap, chain_type, prompt):\n",
    "    #Instantiate LLM model gpt-3.5-turbo-16k\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OpenAI.api_key)\n",
    "\n",
    "    #Load PDF file\n",
    "    loader = PyPDFLoader(pdf_file_path)\n",
    "    docs_raw = loader.load()\n",
    "\n",
    "    #Create multiple documents\n",
    "    docs_raw_text = [doc.page_content for doc in docs_raw]\n",
    "\n",
    "    #Split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs_chunks = text_splitter.create_documents(docs_raw_text)\n",
    "\n",
    "    #Create multiple prompts\n",
    "\n",
    "\n",
    "    #Summarize the chunks\n",
    "\n",
    "    #Return the summary\n",
    "    return chain.run(docs_chunks)\n",
    "\n",
    "#streamlit app main() function\n",
    "\n",
    "def main():\n",
    "    #Set page config and title\n",
    "    st.set_page_config(page_title=\"PDF Summarizer\", page_icon=\":book:\", layout=\"wide\")\n",
    "    st.title(\" \")\n",
    "\n",
    "    #Add custom sliders and selectbox for more user interaction\n",
    "\n",
    "\n",
    "    #Display warning message\n",
    "\n",
    "\n",
    "    #Input pdf file path\n",
    "    pdf_file_path = st.text_input(\"Enter PDF file path:\")\n",
    "\n",
    "    #Prompt input\n",
    "    user_prompt = st.text_input(\"Enter prompt:\")\n",
    "\n",
    "    #Summarize button\n",
    "    if st.button(\"Summarize\"):\n",
    "        #Summarize pdf\n",
    "        summary = summarize_pdf(pdf_file_path, chunk_size, chunk_overlap, chain_type, user_prompt)\n",
    "        st.write(summary)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xn7-oPQOPNUD"
   },
   "outputs": [],
   "source": [
    "!wget -q -O - ipv4.icanhazip.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "141g6WFTPVbM"
   },
   "outputs": [],
   "source": [
    "!streamlit run app.py & npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
